#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from re import search, compile
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
import os, logging
from difflib import SequenceMatcher
from pathlib import Path
from time import time
from sys import version_info, platform
import bart
from bart.scripts.version import __version__
from bart.scripts.kma import ipe
from bart.scripts.refseq_masher import choose_scheme
from bart.scripts.ascii import bart_ascii

__author__ = "Tom Stanton"
__license__ = "MIT"
__maintainer__ = "Tom Stanton"
__email__ = "tomdstanton@gmail.com"
__status__ = "Development"

def parse_args():
    parser = ArgumentParser(add_help=False, usage="bart input.fq.gz [options] > outfile.tab")
    parser.add_argument('input', nargs='+', type=Path, help=SUPPRESS)
    parser.print_usage = parser.print_help
    options = parser.add_argument_group('--options [defaults]')
    options.add_argument('-s', metavar='scheme', nargs='?', type=str, const='', help='''force scheme, see bart-update -s''')
    options.add_argument('-p', type=int, metavar='[95]', default=95, help='''template percent cutoff''')
    options.add_argument('-o', metavar='input path', nargs='?', type=str, const='', help='''export alleles to fasta''')
    options.add_argument('-k', action='store_true', default=False, help='''keep temporary files''')
    options.add_argument('-l', metavar='cwd', nargs='?', type=str, const='', help='''create logfile''')
    options.add_argument('-t', type=int, default=4, metavar='[4]', help='''threads''')
    options.add_argument('-q', action='store_true', default=False, help='''silence messages''')
    options.add_argument('-h', action='help', help='show this help message and exit')
    args = parser.parse_args()
    return args


def main():
    db_path = f'{os.path.dirname(bart.__file__)}/db'
    os.makedirs(db_path, exist_ok=True)
    os.makedirs(f'{db_path}/indexes', exist_ok=True)
    os.makedirs(f'{db_path}/mapping', exist_ok=True)
    logger = logging.getLogger('root')
    logging.basicConfig(format='%(asctime)s | %(message)s', datefmt="%H:%M:%S")
    logger.setLevel(logging.DEBUG)
    args = parse_args()
    if args.q:
        logger.setLevel(logging.ERROR)
    if args.l is not None:
        logpath = args.l
        if logpath == '':
            logpath = f'{os.getcwd()}/bart_{str(time()).split(".")[0]}.log'
        logger.addHandler(logging.FileHandler(logpath))
    logger.info(f'this is bart {__version__} by {__author__}')
    logger.info(f'running on {platform} with Python {str(version_info[:3])[1:-1].replace(", ", ".")}')

##### Check input #####
    threads = str(args.t)
    if args.t > os.cpu_count():
        logger.warning(f'number of threads exceeds available CPUs')
        threads = str(os.cpu_count())
    logger.info(f'using {threads} threads')

    suffixes = ['_R[12]\.(fastq(?:\.gz)?)$', '_R[12]_[0-9]+?\.(fastq(?:\.gz)?)$',
                '_R[12].[0-9]+?\.(fastq(?:\.gz)?)$', '_[12]\.(fastq(?:\.gz)?)$',
                '_[12]_[0-9]+?\.(fastq(?:\.gz)?)$', '_[12].[0-9]+?\.(fastq(?:\.gz)?)$',
                '_R[12]\.(fq(?:\.gz)?)$', '_R[12]_[0-9]+?\.(fq(?:\.gz)?)$',
                '_R[12].[0-9]+?\.(fq(?:\.gz)?)$', '_[12]\.(fq(?:\.gz)?)$',
                '_[12]_[0-9]+?\.(fq(?:\.gz)?)$', '_[12].[0-9]+?\.(fq(?:\.gz)?)$']

    r = compile('|'.join(suffixes))
    pairs = defaultdict(list)
    for i in args.input:
        if not os.path.isfile(i):
            logger.error(f'{i} is not a valid file')
        else:
            filename = str(i)
            s = search(r, filename)
            if s:
                pairs[filename.replace(s.group(0), '')].append(str(i))
            else:
                logger.error(f'{i} is not a fastq file')

    if not any(os.scandir(f'{db_path}/indexes')):
        logger.info("no indexes found, building from PubMLST")
        os.system("bart-update -p")

    start = time()

##### Loop over read-pair dict #####
    for reads in list(pairs):
        sample = os.path.basename(reads)
        if len(pairs[reads]) != 2:
            logger.error(f'no read pair found for {sample}: {" ".join(pairs[reads])}')
            continue
        logger.info(f'read pair for {sample}: {" ".join(pairs[reads])}')

        if args.s is not None:
            if not args.s in [f.name.split('.')[0] for f in os.scandir(f'{db_path}/mapping/')]:
                exit(logger.error(f'{args.s} not a valid scheme, use bart-update -s to see valid schemes'))
            else:
                scheme = args.s

##### Choose Scheme #####
        else: scheme = choose_scheme(pairs, reads, db_path)
        if not scheme: continue

##### Run mapping and parse results #####
        # [0]Template [1]Score [2]Expected [3]Template_length [4]Template_Identity
        # [5]Template_Coverage [6]Query_Identity [7]Query_Coverage [8]Depth [9]q_value
        ipe(pairs[reads], f'/tmp/{sample}', str(args.p), f'{db_path}/indexes/{scheme}', threads)
        res_dict, sub_hits = {}, []  # make a dictionary of kma results where allele is the key
        #with open(f'/tmp/{sample}.res', newline='\n') as res:
        with open('/tmp/1483797.res', newline='\n') as res:
            r = res.read().splitlines()[1:] # skip header
        if len(r) == 0:  # EXIT IF NO HITS
            logger.error('no hits found')
            #continue
        else:
            logger.info(f'{len(r)} hits found')
            for line in r:
                result = [x.strip(' ') for x in line.split('\t')][:-1] # p_value unnecessary, always the same
                allele = result[0]
                gene = result[0].rsplit('_', 1)[0] # make gene name the key
                result[0] = result[0].rsplit('_', 1)[1] # make allele number first element

                if gene in res_dict.keys(): # if the gene is already in results dict
                    if float(result[4]) > float(res_dict[gene][4]): # pick one with higher percid
                        sub_hits.append('{}_{}'.format(gene, res_dict[gene][0]))
                        res_dict[gene] = result
                    elif float(result[9]) > float(res_dict[gene][9]): # next, pick one with higher qscore
                        sub_hits.append('{}_{}'.format(gene, res_dict[gene][0]))
                        res_dict[gene] = result
                    else:
                        sub_hits.append(allele)
                else:
                    res_dict[gene] = result

##### Assign profile via a range of methods #####
        #with open(f'{db_path}/mapping/{scheme}.tab', newline='\n') as tab:
        with open(f'{db_path}/mapping/Citrobacter_freundii.tab', newline='\n') as tab:
            s = tab.read().splitlines()
        headers = s[0].split('\t')[1:]
        scheme_dict = {}  # make a dictionary of the scheme where ST is the key
        for line in s[1:]: # first column is ST
            v = line.split('\t')
            scheme_dict[int(v[0])] = {headers[i]: v[1:][i] for i in range(len(headers))}

        # make a list of only genes in headers
        genes = [g for g in headers if g not in ['clonal_complex', 'species', 'CC', 'Lineage']]
        exact = []
        no_hit = []
        for i in genes:
            if i in res_dict.keys(): # check if gene in scheme was a hit in results
                if float(res_dict[i][4]) >= 100 and float(res_dict[i][5]) >= 100: # percid and coverage
                    exact.append(i) # make a list of genes with exact matches
            else:
                no_hit.append(i)
                logger.info('no hit for ' + i)
                for p in scheme_dict.keys(): # check if scheme considers missing allele
                    if scheme_dict[p][i] == '0':
                        logger.info(f'this scheme considers missing {i} alleles, setting {i} allele to 0')
                        res_dict[i] = ['0'] + ['missing'] * 10
                        exact.append(i)
                        break

        [genes.remove(gene) for gene in no_hit if gene not in exact] # remove no-hits if scheme doesn't consider 0 as allele
        not_exact = list({*exact} ^ {*res_dict.keys()}) # make a list of non-exact genes

        # Quickly filter profiles based on exact hits #
        profile_dict = dict(scheme_dict)
        for i in exact:
            for st in list(profile_dict.keys()):
                if scheme_dict[st][i] != res_dict[i][0]:
                    profile_dict.pop(st)

        # Use LCS to find closest profiles #
        if len(profile_dict) != 1:
            logger.info('no exact profile match, finding closest')
            profile_dict = {}

            # LCS function
            def profile_LCS(in_dict):
                # 1/7 = 0.14, so at least 1 allele has to match
                r, t = 0.14, [] # set ratio to 0.14 to filter low hits
                profile = [in_dict[gene][0] for gene in genes]
                for st in scheme_dict.keys():
                    seqs = [scheme_dict[st][gene] for gene in genes], [scheme_dict[st][gene] for gene in exact]
                    for seq in seqs: # gene and exact matching can give different results, so run both
                        s = SequenceMatcher(None, profile, seq).ratio()
                        if s > r:
                            r = s # this is a problem because the first ST will always be appended
                            t.append(st)
                t = [i for i in t if i != 1] # remove result for ST1, assumes first ST in scheme is always 1
                # repeat for first ST
                seqs = [scheme_dict[1][gene] for gene in genes], [scheme_dict[1][gene] for gene in exact]
                for seq in seqs:
                    s = SequenceMatcher(None, seq, profile).ratio()
                    if s > r:
                        r = s
                        t.append(1)
                return r, t # returns highest matching ratio and best STs

            ratio, topst = profile_LCS(res_dict)

            if len(sub_hits) > 0: # see sub-hits match profiles better
                for allele in sub_hits:
                    result = ''.join(x.replace(' ','') for x in r if allele in x).split('\t')
                    allele = result[0]
                    gene = result[0].rsplit('_', 1)[0]  # make gene name the key
                    result[0] = result[0].rsplit('_', 1)[1]
                    tmp_dict = dict(res_dict)
                    tmp_dict[gene] = result
                    r_sub, t_sub = profile_LCS(tmp_dict)
                    if r_sub > ratio:
                        logger.info(f'sub-hit {allele} matches '
                                    f'{len(t_sub)} profiles at {int(r_sub * 100)}% '
                                    f'compared to {int(ratio * 100)}% for {gene}_{res_dict[gene][0]}')
                        ratio = r_sub # update top ratio for better sub-hits
                        res_dict[gene] = result # update results with sub-hit
                        topst += t_sub

            if len(topst) > len(set(topst)): # choose most likely STs from gene and exact matching, will appear twice
                for st in set(topst): # make top sts unique and iterate
                    if topst.count(st) == 2: # max value is 2
                        profile_dict[st] = scheme_dict[st]
            else:
                for st in topst:
                    profile_dict[st] = scheme_dict[st]

            if len(profile_dict) != 0:
                logger.info(f'displaying {len(profile_dict)} profile(s) with {int(ratio * 100)}% match')
            else:
                logger.warning(f'no profile matches')

##### Printing output #####

############################################################################
        # add info in output header for non-exact matches
        # out is always the numbers from profile_dict but with info from res_dict

        out = sample + '\t' + scheme + '\t' # this part of the output never changes

        if len(profile_dict) == 0: # just print results if no profile match
            st = '?'
            result = ''
            for gene in res_dict.keys():
                result += f'{res_dict[gene]}({res_dict[gene][0]})'

        else:
            for k in profile_dict.keys():
                st = str(k)
                result = ''
                if ratio:
                    st += f' ({int(ratio * 100)}%)'

                #genA(15),14

                for gene, allele in profile_dict[k].items(): # iterate through dictionary for each st
                    if gene in res_dict.keys():
                        if float(res_dict[gene][4]) < 100 and float(res_dict[gene][5]) < 100:
                            result += '\t' + f'{gene}({allele}?)'

                        elif float(res_dict[gene][4]) < 100:
                            result += '\t' + f'{gene}({allele})'

                        elif float(res_dict[gene][5]) < 100:
                            result += '\t' + f'{gene}({allele})'

                        # if res_dict[gene][0] != allele:
                        

                    elif gene in ['clonal_complex', 'species', 'CC', 'Lineage']:
                        if allele:
                            result += '\t' + f'{gene}({allele})'


        # up here we can create the standardised output
        # v: plus extra verbosity
        # vv: plus extra verbosity plus extra stats


        print('Sample\tScheme\tST\t' + "\t".join([str(x) for x in headers]))
        if len(profile_dict) == 0:
            out = sample + '\t' + scheme + '\t' + '?'
            for gene in res_dict.keys():
                out += '\t' + res_dict[gene][0]
            print(out)
        else: # just print results if no profile match
            for st in profile_dict.keys():
                out = sample + '\t' + scheme + '\t' + str(st)
                for k, v in profile_dict[st].items():
                    if k in [s.strip('~').strip('!').strip('*') for s in headers]:
                        if v != '':
                            out += '\t' + v
                    else:
                        out += '\t-'
                print(out)

############################################################################

        if args.o is not None:
            outfile = args.o
            if outfile == '':
                delim = '.'
                if '_' in pairs[reads][0]:
                    delim = '_'
                outfile = f'{pairs[reads][0].split(delim, 1)[0]}_alleles.fna'
            with open(f'/tmp/{sample}.fsa', newline='\n') as fna, open(outfile, 'wt') as out:
                for seq in fna.read().split('>')[1:]:
                    for k, v in res_dict.items():
                        if f'{k}_{v[0]}' in seq:
                            if k in not_exact:
                                out.write('>{}_novel\n{}'.format(k, seq.split("\n", 1)[1]))
                            else:
                                out.write('>{}_{}\n{}'.format(k, v[0], seq.split("\n", 1)[1]))
            logger.info(f'written alleles to {outfile}')

##### Cleanup #####
        if not args.k:
            logger.info(f'cleaning up files in /tmp/')
            for f in os.listdir('/tmp/'):
                if sample in f:
                    os.remove(f'/tmp/{f}')
        else:
            logger.info(f'kept files in /tmp/')

    logger.info(f'completed in {"{:.1f}".format(time() - start)} seconds{bart_ascii()}')


if __name__ == '__main__':
    main()
