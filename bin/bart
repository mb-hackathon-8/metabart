#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from re import search, compile
from collections import defaultdict
from argparse import ArgumentParser, SUPPRESS
import os
from pathlib import Path
from time import time
import logging
from difflib import SequenceMatcher
from sys import version_info, platform
from bart.version import __version__
from bart.kma import ipe
from bart import finch
from bart.ascii import bart_ascii

__author__ = "Tom Stanton"
__license__ = "MIT"
__maintainer__ = "Tom Stanton"
__email__ = "tomdstanton@gmail.com"
__status__ = "Development"

def parse_args():
    parser = ArgumentParser(add_help=False, usage="bart input.fq.gz [options] > outfile.tab")
    parser.add_argument('input', nargs='+', type=Path, help=SUPPRESS)
    parser.print_usage = parser.print_help
    options = parser.add_argument_group('--options [defaults]')
    options.add_argument('--scheme', metavar='scheme', nargs='?', type=str, const='', help='''force scheme, see bart-update -s''')
    options.add_argument('--exact', action='store_true', default=False, help='''match profile from exact hits only''')
    options.add_argument('--percid', type=int, metavar='[95]', default=95, help='''template percent cutoff''')
    options.add_argument('--info', action='store_true', default=False, help='''add genome info to output table''')
    options.add_argument('-o', metavar='input path', nargs='?', type=str, const='', help='''export alleles to fasta''')
    options.add_argument('-k', action='store_true', default=False, help='''keep temporary files''')
    options.add_argument('-l', metavar='cwd', nargs='?', type=str, const='', help='''create logfile''')
    options.add_argument('-t', type=int, default=4, metavar='[4]', help='''threads''')
    options.add_argument('-q', action='store_true', default=False, help='''silence messages''')
    options.add_argument('-h', action='help', help='show this help message and exit')
    args = parser.parse_args()
    return args


def main():
    bin_path = os.path.join(os.path.dirname(os.path.dirname(__file__)))
    os.makedirs(f'{bin_path}/db/indexes', exist_ok=True)
    os.makedirs(f'{bin_path}/db/mapping', exist_ok=True)
    db_path = f'{bin_path}/db'
    logger = logging.getLogger('root')
    logging.basicConfig(format='%(asctime)s | %(message)s', datefmt="%H:%M:%S")
    logger.setLevel(logging.DEBUG)
    args = parse_args()
    if args.q:
        logger.setLevel(logging.ERROR)
    if args.l is not None:
        logpath = args.l
        if logpath == '':
            logpath = f'{os.getcwd()}/bart_{str(time()).split(".")[0]}.log'
        logger.addHandler(logging.FileHandler(logpath))
    logger.info(f'this is bart {__version__} by {__author__}')
    logger.info(f'running on {platform} with Python {str(version_info[:3])[1:-1].replace(", ", ".")}')

    if platform == 'linux':
        finch_binary = f'{bin_path}/bart/finch-linux64-v0.3.0'
    elif platform == 'darwin':
        finch_binary = f'{bin_path}/bart/finch-mac64-v0.3.0'
    else:
        exit(logger.error(f'finch binary not compatible with {platform}'))

    ### Check input filetypes and create read-pair dict ###
    threads = str(args.t)
    if args.t > os.cpu_count():
        logger.warning(f'number of threads exceeds available CPUs')
        threads = str(os.cpu_count())
    logger.info(f'using {threads} threads')

    suffixes = ['_R[12]\.(fastq(?:\.gz)?)$', '_R[12]_[0-9]+?\.(fastq(?:\.gz)?)$',
                '_R[12].[0-9]+?\.(fastq(?:\.gz)?)$', '_[12]\.(fastq(?:\.gz)?)$',
                '_[12]_[0-9]+?\.(fastq(?:\.gz)?)$', '_[12].[0-9]+?\.(fastq(?:\.gz)?)$',
                '_R[12]\.(fq(?:\.gz)?)$', '_R[12]_[0-9]+?\.(fq(?:\.gz)?)$',
                '_R[12].[0-9]+?\.(fq(?:\.gz)?)$', '_[12]\.(fq(?:\.gz)?)$',
                '_[12]_[0-9]+?\.(fq(?:\.gz)?)$', '_[12].[0-9]+?\.(fq(?:\.gz)?)$']

    r = compile('|'.join(suffixes))
    pairs = defaultdict(list)
    for i in args.input:
        if not os.path.isfile(i):
            logger.error(f'{i} is not a valid file')
        else:
            filename = str(i)
            s = search(r, filename)
            if s:
                pairs[filename.replace(s.group(0), '')].append(str(i))
            else:
                logger.error(f'{i} is not a fastq file')

    if not any(os.scandir(f'{db_path}/indexes')):
        logger.info("no indexes found, building from PubMLST")
        os.system("bart-update -p")

    start = time()
    ### Loop over read-pair dict ###
    for name in list(pairs):
        sample = os.path.basename(name)
        logger.info(f'read pair for {sample}: {" ".join(pairs[name])}')
        sketch = f'/tmp/{sample}.sk'
        if args.scheme is not None:
            if not args.scheme in [f.name.split('.')[0] for f in os.scandir(f'{db_path}/mapping/')]:
                exit(logger.error(f'{args.scheme} not a valid scheme, use bart-update -s to see valid schemes'))
            else:
                scheme = args.scheme
        else:
            if not os.path.isfile(sketch):
                finch.sketch_input(finch_binary, pairs[name], sketch)
            finch_out = finch.dist(sketch, db_path, finch_binary)
            logger.info(f'closest refseq genome is {finch_out}')
            d = [f.name.split('.')[0] for f in os.scandir(f'{db_path}/mapping/')]
            # First check genus

            if 'Shigella' in finch_out:
                d = ['Escherichia_coli#1']
                logger.warning('Shigella uses the Escherichia_coli#1 scheme')
            else:
                d = [k for k in d if finch_out.split(' ')[0] in k]

            if len(d) < 1: # More critical if no matching genus, good idea to exit program here and prompt to force scheme
                logger.error(f"no matching schemes for {finch_out.split(' ')[0]}, check available schemes with bart --schemes")

            elif len(d) == 1:
                logger.info(f"genus match for scheme {d[0]}")
                scheme = d[0]

            elif len(d) > 1:  # check species now, if #1/#2 like in Ab, need to account for that
                logger.info(f"{len(d)} matching schemes for genus {finch_out.split(' ')[0]}")
                species, s = set([g.split('_')[1].split('#')[0] for g in d]), []
                for i in species:
                    if SequenceMatcher(None, finch_out.split(' ')[1], i).ratio() == 1:
                        s = [k for k in d if i in k]

                if len(s) < 1:
                    logger.warning(f"no matching schemes for species {finch_out.split(' ')[1]}")
                    # first go with spp, then try genus scheme with most alleles
                    if 'spp' in species:
                        d = [k for k in d if 'spp' in k]
                    else:
                        top_profiles = 0
                        for i in species:
                            with open(f'{db_path}/mapping/{finch_out.split(" ")[0]}_{i}.tab', "r") as f:
                                profiles = len(f.readlines())
                                if profiles > top_profiles:
                                    top_profiles = profiles
                                    d = [f'{finch_out.split(" ")[0]}_{i}']
                    scheme = d[0]
                    logger.warning(f"{d[0]} might cover your species")

                else:
                    logger.info(f"matched species {finch_out.split(' ')[1]} to scheme {s[0]}")
                    scheme = s[0]

        ipe(pairs[name], f'/tmp/{sample}', str(args.percid),
            f'{db_path}/indexes/{scheme}', threads)

        # make a dictionary of kma results where allele is the key
        with open(f'/tmp/{sample}.res', newline='\n') as res:
            r = res.read().splitlines()
        res_dict = {}
        for line in r[1:]:
            v = line.split('\t')
            v = [x.strip(' ') for x in v]
            k = v[0].rsplit('_', 1)[0]
            v[0] = v[0].rsplit('_', 1)[1]
            if k in list(res_dict):
                if float(v[4]) > float(res_dict[k][4]):
                    res_dict[k] = v
                else:
                    continue
            else:
                res_dict[k] = v

        if len(res_dict) > 0:
            logger.info(f'{len(res_dict)} hits found')
        else:
            logger.error('no hits found')
            continue

        # make a dictionary of the scheme where ST is the key
        with open(f'{db_path}/mapping/{scheme}.tab', newline='\n') as tab:
            s = tab.read().splitlines()
        headers, scheme_dict = s[0].split('\t')[1:], {}
        for line in s[1:]: #first column is ST
            v = line.split('\t')
            scheme_dict[int(v[0])] = {headers[i]: v[1:][i] for i in range(len(headers))}

        # make a list of only genes in headers
        genes, exact, no_hit = [g for g in headers if g not in ['clonal_complex', 'species', 'CC', 'Lineage']], [], []

        # add info in output header for non-exact matches and make a list of genes with exact matches
        for x, i in enumerate(headers):
            if i in genes:
                if i in res_dict.keys():
                    if float(res_dict[i][4]) < 100 and float(res_dict[i][5]) < 100:
                        headers[x] = f'{i}!'
                    elif float(res_dict[i][4]) < 100:
                        headers[x] = f'{i}*'
                    elif float(res_dict[i][5]) < 100:
                        headers[x] = f'{i}?'
                    else:
                        exact.append(i)
                else:
                    no_hit.append(i)
                    logger.info('no hit for ' + i)
                    for p in scheme_dict.keys():
                        if scheme_dict[p][i] == '0':
                            logger.info(f'this scheme considers missing {i} alleles, setting {i} allele to 0')
                            res_dict[i] = ['0'] + ['missing'] * 10
                            exact.append(i)
                            break

        not_exact = list({*exact} ^ {*res_dict.keys()})
        if len(not_exact) >= 1:
            logger.info(f'potential novel allele for {", ".join(not_exact)}')

        # Profile Choosing
        exact = list({*genes} ^ {*not_exact})
        profile_dict = dict(scheme_dict)
        # need to make a copy in case no matches and scheme dict is deleted (not pythonic)
        if args.exact is False:
            for i in not_exact:
                logger.info(f'assuming {res_dict[i][0]} is closest allele for {i}')
            for i in genes:
                for st in list(profile_dict.keys()):
                    if scheme_dict[st][i] != res_dict[i][0]:
                        profile_dict.pop(st)

            if len(profile_dict) < 1:
                logger.info(f'no profile matches, dropping {", ".join(not_exact)}')
                profile_dict = dict(scheme_dict)
                for i in exact:
                    for st in list(profile_dict.keys()):
                        if scheme_dict[st][i] != res_dict[i][0]:
                            profile_dict.pop(st)

            if len(profile_dict) > 1:
                logger.info(f'no exact profile match, displaying {len(profile_dict)} close matches')

            if len(profile_dict) == 0:
                logger.error(f'no profile matches')

        if args.exact is True:
            logger.info(f'only considering exact hits for profile matching: {", ".join(exact)}')
            profile_dict = dict(scheme_dict)
            for i in exact:
                for st in list(profile_dict.keys()):
                    if scheme_dict[st][i] != res_dict[i][0]:
                        profile_dict.pop(st)

        # Printing output to tab-separated STDOUT for piping
        info = []
        if args.info:
            if not os.path.isfile(sketch):
                finch.sketch_input(finch_binary, pairs[name], sketch)
            info = finch.info(sketch, finch_binary)
        if len(info) > 0:
            headers += ['genome_size', 'ave_depth', '%GC']
        print('Sample\tScheme\tST\t' + "\t".join([str(x) for x in headers]))

        if len(profile_dict) == 0:
            out = sample + '\t' + scheme + '\t' + '-'
            for gene in res_dict.keys():
                out += '\t' + res_dict[gene][0]
            if len(info) > 0:
                out += '\t{}\t{}\t{}'.format(info[0], info[1], info[2])
            print(out)
        else:
            for st in profile_dict.keys():
                out = sample + '\t' + scheme + '\t' + str(st)
                for k, v in profile_dict[st].items():
                    if k in [s.strip('?').strip('!').strip('*') for s in headers]:
                        if v != '':
                            out += '\t' + v
                    else:
                        out += '\tno hit'
                if len(info) > 0:
                    out += '\t{}\t{}\t{}'.format(info[0], info[1], info[2])
                print(out)

        if args.o is not None:
            outfile = args.o
            if outfile == '':
                delim = '.'
                if '_' in pairs[name][0]:
                    delim = '_'
                outfile = f'{pairs[name][0].split(delim, 1)[0]}_alleles.fna'
            with open(f'/tmp/{sample}.fsa', newline='\n') as fna, open(outfile, 'wt') as out:
                for seq in fna.read().split('>')[1:]:
                    for k, v in res_dict.items():
                        if f'{k}_{v[0]}' in seq:
                            if k in not_exact:
                                out.write('>{}_novel\n{}'.format(k, seq.split("\n", 1)[1]))
                            else:
                                out.write('>{}_{}\n{}'.format(k, v[0], seq.split("\n", 1)[1]))
            logger.info(f'written alleles to {outfile}')

        # Cleanup
        if not args.k:
            logger.info(f'cleaning up files in /tmp/')
            for f in os.listdir('/tmp/'):
                if sample in f:
                    os.remove(f'/tmp/{f}')
        else:
            logger.info(f'kept files in /tmp/')

    logger.info(f'completed in {"{:.1f}".format(time() - start)} seconds{bart_ascii()}')


if __name__ == '__main__':
    main()
