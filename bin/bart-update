#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from argparse import ArgumentParser
import os
from re import DOTALL, findall
from requests import get
from pathlib import Path
import logging
import asyncio
from shutil import copyfile
from sys import version_info, platform
import bart
from bart.version import __version__
from bart.kma import index

__author__ = "Tom Stanton"
__license__ = "MIT"
__maintainer__ = "Tom Stanton"
__email__ = "tomdstanton@gmail.com"
__status__ = "Development"

def parse_args():
    parser = ArgumentParser(add_help=False, usage="bart-update [options]")
    parser.add_argument('-s', '--schemes', action='store_true', default=False, help='print available MLST schemes')
    parser.add_argument('-p', '--pubmlst', action='store_true', default=False, help='update pubMLST schemes')
    parser.add_argument('-a', '--add', nargs='*', type=Path, help='path to custom scheme fasta and csv')
    parser.add_argument('-r', '--remove', type=str, nargs='*', help='name of scheme(s) to remove')
    parser.add_argument("-h", action="help", help='show this help message and exit')
    args = parser.parse_args()
    return args


def main():
    bin_path = f'{os.path.dirname(bart.__file__)}'
    db_path = f'{os.path.dirname(bin_path)}/db'
    logger = logging.getLogger('root')
    logging.basicConfig(format='%(asctime)s | %(message)s', datefmt="%H:%M:%S")
    logger.setLevel(logging.DEBUG)

    Path(f'{db_path}/mapping').mkdir(parents=True, exist_ok=True)
    Path(f'{db_path}/indexes').mkdir(parents=True, exist_ok=True)

    args = parse_args()

    if args.schemes:
        d = [f.name.split('.')[0] for f in os.scandir(f'{db_path}/mapping/')]
        exit(print(*sorted(d), sep="\n"))

    logger.info(f'this is bart {__version__} by {__author__}')
    logger.info(f'running on {platform} with Python {str(version_info[:3])[1:-1].replace(", ", ".")}')

    if args.add:
        names = []
        logger.info(f'adding scheme from: {str(args.add)}')
        for i in args.add:
            if os.path.isfile(i):
                names.append(os.path.basename(i).split('.', -1)[0])
                with open(i, 'rb') as f:
                    first = next(f).decode()
                if first.startswith('>'):
                    fasta = i
                    logger.info(f'{i} is a valid fasta file')
                elif first.startswith('ST\t'):
                    mapping = i
                    logger.info(f'{i} is a valid mapping file')
                else:
                    break
            else:
                exit(logger.error(f'{i} is not a valid file'))

        # remove dupes to see if name is the same
        names = list(dict.fromkeys(names))

        if len(names) > 1:
            exit(logger.error(f'files need to have same names, not: {names[0]}'))
        copyfile(mapping, f'{db_path}/mapping/{names[0]}.tab')
        with open(fasta, 'r') as f:
            index(f.read(), f'{db_path}/indexes/{names[0]}')

    if args.remove:
        for name in args.remove:
            logger.info(f'removing {db_path}/mapping/{name}.tab')
            os.remove(f'{db_path}/mapping/{name}.tab')
            for i in ['.comp.b', '.seq.b', '.length.b', '.name']:
                logger.info(f'removing {db_path}/indexes/{name}{i}')
                os.remove(f'{db_path}/indexes/{name}{i}')

    if args.pubmlst:
        def background(f):
            def wrapped(*args, **kwargs):
                return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)
            return wrapped

        @background
        def build_mlst(s):
            scheme, urls = s.split('\n'), []
            name = scheme[0].replace(' ', '_').replace('/', '_').strip('.')
            for l in scheme:
                if any(ft in l for ft in ['csv', 'fasta']):
                    urls.append(l.split('>')[1].split('<')[0])
            with open(f'{db_path}/mapping/{name}.tab', 'ab') as f:
                f.write(get(urls[0]).content)
            logger.info(f'written scheme map to {db_path}/mapping/{name}.tab')
            i = ''
            for url in urls[1:]:
                i += get(url).text
            index(i, f'{db_path}/indexes/{name}')

        # this deletes files if they already exist
        [f.unlink() for f in Path(f'{db_path}/mapping/').glob("*") if f.is_file()]
        for species in findall('<species>(.*?)</species>', get('https://pubmlst.org/static/data/dbases.xml').text, DOTALL):
            build_mlst(species)


if __name__ == '__main__':
    main()
